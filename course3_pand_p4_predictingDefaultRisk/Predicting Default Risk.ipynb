{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">TASKS</span>\n\n* update data types\n* Do I split new_applicants data 70% and 30%... or do I use the training data given to me? based on titanic video I might split my training data, to train the model, then use unknown dataset to old_applicants the model... 3 vids can help... \n    * [data school](https://www.youtube.com/watch?v=RlQuVL6-qe8&index=4&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A): \n    * [packt](https://www.youtube.com/watch?v=Eqv98w1ukZk): splits data set as projedct instructions describe\n    * [titanic](https://www.youtube.com/watch?v=VCJdg7YBbAQ): describes creating dummies from dataset\n    * [iris google dev]([iris google developers](https://www.youtube.com/watch?v=tNa99PG8hR8&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=2)\n\n* Create dummies on fields with multiple numeric/text values (e.g. sex, ticket class)\n* Correlation & P-values, select predictors\n    * watch udacity videos and other videos if needed\n    \n* Does target variable also need to be converted to numeric, or is that only an Altryx issue???\n    * if so create new column np.where([old_applicants[\"Credit-Application-Result\"] == 'Creditworthy', 1, 0)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# RESOURCES\n\n* ## [project details](https://classroom.udacity.com/nanodegrees/nd008t/parts/54e2103b-5630-497a-bc37-c05d45cda549/modules/12c50013-ad11-4980-88a0-13d474cda9b8/lessons/ee56f886-070e-40ca-bfc8-cab2c5cdde7d/concepts/ac7bf309-3e98-4a2f-ad4e-555905d7cd07)\n* ## [rubric](https://review.udacity.com/#!/rubrics/265/view)\n* ## [main project folder](https://udacity-travismgillespie.notebooks.azure.com/j/tree)\n* ## variance\n    * ### [use R-squared to describe variance](https://classroom.udacity.com/nanodegrees/nd008t/parts/9cd2f005-f9b1-4953-ba02-ad65805b2a4a/modules/fc4c1ffe-01f6-4c11-b38b-646ecf1d3c59/lessons/576552b9-a1b4-45be-9428-572331a4e186/concepts/82bfe969-921b-4175-adb5-797e84ba6107): also look into [project 2](https://udacity-travismgillespie.notebooks.azure.com/j/notebooks/project2/Data%20Wrangling.ipynb) diamond catalog to see if I calculated correlation p and r-squared at same time... may have used a corr-matrix\n* ## feature selection\n    * ### [Packt: select features in machine learning](https://hub.packtpub.com/selecting-statistical-based-features-in-machine-learning-application/)\n    * ### [use p-value & correlation to select predictor variable](https://classroom.udacity.com/nanodegrees/nd008t/parts/9cd2f005-f9b1-4953-ba02-ad65805b2a4a/modules/fc4c1ffe-01f6-4c11-b38b-646ecf1d3c59/lessons/576552b9-a1b4-45be-9428-572331a4e186/concepts/82bfe969-921b-4175-adb5-797e84ba6107)\n    * ### [p values donâ€™t help in feature selection](https://www.quora.com/How-did-you-use-p-value-for-feature-selection)\n    * ### [Feature selection - univariate selection](https://blog.datadive.net/selecting-good-features-part-i-univariate-selection/)\n    * ### [predictor variables](https://classroom.udacity.com/nanodegrees/nd008t/parts/9cd2f005-f9b1-4953-ba02-ad65805b2a4a/modules/fc4c1ffe-01f6-4c11-b38b-646ecf1d3c59/lessons/576552b9-a1b4-45be-9428-572331a4e186/concepts/631d190c-8626-4dd7-92df-f5bd96913c48): udacity\n    * ### [explanatory variables (aka predictor variables)](https://classroom.udacity.com/nanodegrees/nd008t/parts/9cd2f005-f9b1-4953-ba02-ad65805b2a4a/modules/fc4c1ffe-01f6-4c11-b38b-646ecf1d3c59/lessons/576552b9-a1b4-45be-9428-572331a4e186/concepts/631d190c-8626-4dd7-92df-f5bd96913c48): udacity\n    * ### [feature selection ex](https://www.youtube.com/watch?v=hhmsHY2vWY4)\n    * ### [feature selection correlation and p-value](https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf)\n* ## coefficients\n    * ### [calculate coefficients](https://classroom.udacity.com/nanodegrees/nd008t/parts/9cd2f005-f9b1-4953-ba02-ad65805b2a4a/modules/fc4c1ffe-01f6-4c11-b38b-646ecf1d3c59/lessons/576552b9-a1b4-45be-9428-572331a4e186/concepts/631d190c-8626-4dd7-92df-f5bd96913c48): watch udacity video\n* ## linear regression\n    * ### [packt ex](https://www.youtube.com/watch?v=Eqv98w1ukZk): good example of seeds and splitting test set\n* ## logistic regression\n    * ### [StatQuest](https://www.youtube.com/watch?v=yIYKR4sgzI8)\n    * ### [data school ex](https://www.youtube.com/watch?v=RlQuVL6-qe8&index=4&list=PL5-da3qGB5ICeMbQuqbbCOQWcS6OYBr5A)\n    * ### [Titanic ex](https://www.youtube.com/watch?v=VCJdg7YBbAQ)\n    * ### [logistic regression ex](https://www.youtube.com/watch?v=1nWFHa6K23w)\n* ## decision tree\n    * ### [iris google developers](https://www.youtube.com/watch?v=tNa99PG8hR8&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal&index=2)\n* ## boosted tree (aka Gradient boosting)\n    * ### [documentation: scikit learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)\n    * ### [gradient boosting ex](https://www.youtube.com/watch?v=gIJHI5jSChM)\n    * ### [gradient boosting ex](https://www.youtube.com/watch?v=sRktKszFmSk)\n    * ### [gradient boosting ex](https://www.youtube.com/watch?v=X3Wbfb4M33w)\n    * ### [gradient boosting ex](https://www.youtube.com/watch?v=2WfKzyi__l4)\n    * ### [ada boosting ex](https://www.youtube.com/watch?v=GM3CDQfQ4sw)\n    * ### [additional boosting reading](https://en.wikipedia.org/wiki/Gradient_boosting)\n* ## forest model (aka random forest model)\n    * ### [documentation: scikit learn](https://scikit-learn.org/stable/modules/ensemble.html#random-forests)\n    * ### [forest model udacity](https://classroom.udacity.com/nanodegrees/nd008t/parts/54e2103b-5630-497a-bc37-c05d45cda549/modules/12c50013-ad11-4980-88a0-13d474cda9b8/lessons/59e0ee88-1a1e-459d-a79e-53ef74c13e77/concepts/65b13e59-9be3-45f8-a6f3-196369dc3c3d)\n    * ### [random forest example](https://www.youtube.com/watch?v=D_2LkhMJcfY)\n    \n* ## backward elemenation\n    * ### [looking up details on SL = 0.05](https://www.kaggle.com/umeshsati54/backward-elimination)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n# not sure which train_test_split to use... are they different?\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cross_validation import train_test_split\n\nfrom sklearn import tree\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train Data Set"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#training set contains one additional column Credit Application Result\nold_applicants_original = pd.read_excel('./data/credit-data-training.xlsx')\nold_applicants = old_applicants_original.copy()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# given provided training set has been cleaned shouldn't need to be modified\n# consider dropping age where nill\n# old_applicants[\"Age-years\"].unique()\n# old_applicants[\"Duration-in-Current-address\"].unique()\nold_applicants.info()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 20 columns):\nCredit-Application-Result            500 non-null object\nAccount-Balance                      500 non-null object\nDuration-of-Credit-Month             500 non-null int64\nPayment-Status-of-Previous-Credit    500 non-null object\nPurpose                              500 non-null object\nCredit-Amount                        500 non-null int64\nValue-Savings-Stocks                 500 non-null object\nLength-of-current-employment         500 non-null object\nInstalment-per-cent                  500 non-null int64\nGuarantors                           500 non-null object\nDuration-in-Current-address          156 non-null float64\nMost-valuable-available-asset        500 non-null int64\nAge-years                            488 non-null float64\nConcurrent-Credits                   500 non-null object\nType-of-apartment                    500 non-null int64\nNo-of-Credits-at-this-Bank           500 non-null object\nOccupation                           500 non-null int64\nNo-of-dependents                     500 non-null int64\nTelephone                            500 non-null int64\nForeign-Worker                       500 non-null int64\ndtypes: float64(2), int64(9), object(9)\nmemory usage: 78.2+ KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## new_applicants Data Set"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#new_applicants set missing one column... Credit Application Result is the result you are tryting to predict\nnew_applicants = pd.read_excel('./data/customers-to-score.xlsx')\n# new_applicants.sort_values('Purpose', inplace=True)\nnew_applicants.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Account-Balance</th>\n      <th>Duration-of-Credit-Month</th>\n      <th>Payment-Status-of-Previous-Credit</th>\n      <th>Purpose</th>\n      <th>Credit-Amount</th>\n      <th>Value-Savings-Stocks</th>\n      <th>Length-of-current-employment</th>\n      <th>Instalment-per-cent</th>\n      <th>Guarantors</th>\n      <th>Duration-in-Current-address</th>\n      <th>Most-valuable-available-asset</th>\n      <th>Age-years</th>\n      <th>Concurrent-Credits</th>\n      <th>Type-of-apartment</th>\n      <th>No-of-Credits-at-this-Bank</th>\n      <th>Occupation</th>\n      <th>No-of-dependents</th>\n      <th>Telephone</th>\n      <th>Foreign-Worker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>No Account</td>\n      <td>9</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>2799</td>\n      <td>None</td>\n      <td>&lt; 1yr</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2</td>\n      <td>1</td>\n      <td>36</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>More than 1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>No Account</td>\n      <td>12</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>2122</td>\n      <td>None</td>\n      <td>&lt; 1yr</td>\n      <td>3</td>\n      <td>None</td>\n      <td>2</td>\n      <td>1</td>\n      <td>39</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>More than 1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No Account</td>\n      <td>24</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>3758</td>\n      <td>Â£100-Â£1000</td>\n      <td>&lt; 1yr</td>\n      <td>1</td>\n      <td>None</td>\n      <td>4</td>\n      <td>4</td>\n      <td>23</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No Account</td>\n      <td>11</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>3905</td>\n      <td>None</td>\n      <td>&lt; 1yr</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2</td>\n      <td>1</td>\n      <td>36</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>More than 1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No Account</td>\n      <td>6</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>1957</td>\n      <td>None</td>\n      <td>1-4 yrs</td>\n      <td>1</td>\n      <td>None</td>\n      <td>4</td>\n      <td>3</td>\n      <td>31</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  Account-Balance  Duration-of-Credit-Month Payment-Status-of-Previous-Credit  \\\n0      No Account                         9        No Problems (in this bank)   \n1      No Account                        12        No Problems (in this bank)   \n2      No Account                        24                           Paid Up   \n3      No Account                        11        No Problems (in this bank)   \n4      No Account                         6        No Problems (in this bank)   \n\n        Purpose  Credit-Amount Value-Savings-Stocks  \\\n0  Home Related           2799                 None   \n1  Home Related           2122                 None   \n2  Home Related           3758           Â£100-Â£1000   \n3  Home Related           3905                 None   \n4  Home Related           1957                 None   \n\n  Length-of-current-employment  Instalment-per-cent Guarantors  \\\n0                        < 1yr                    2       None   \n1                        < 1yr                    3       None   \n2                        < 1yr                    1       None   \n3                        < 1yr                    2       None   \n4                      1-4 yrs                    1       None   \n\n   Duration-in-Current-address  Most-valuable-available-asset  Age-years  \\\n0                            2                              1         36   \n1                            2                              1         39   \n2                            4                              4         23   \n3                            2                              1         36   \n4                            4                              3         31   \n\n  Concurrent-Credits  Type-of-apartment No-of-Credits-at-this-Bank  \\\n0  Other Banks/Depts                  1                More than 1   \n1  Other Banks/Depts                  1                More than 1   \n2  Other Banks/Depts                  1                          1   \n3  Other Banks/Depts                  1                More than 1   \n4  Other Banks/Depts                  2                          1   \n\n   Occupation  No-of-dependents  Telephone  Foreign-Worker  \n0           1                 2          1               1  \n1           1                 2          1               2  \n2           1                 1          1               1  \n3           1                 2          1               1  \n4           1                 1          1               1  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "new_applicants data set has no null values."
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_applicants.info()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 19 columns):\nAccount-Balance                      500 non-null object\nDuration-of-Credit-Month             500 non-null int64\nPayment-Status-of-Previous-Credit    500 non-null object\nPurpose                              500 non-null object\nCredit-Amount                        500 non-null int64\nValue-Savings-Stocks                 500 non-null object\nLength-of-current-employment         500 non-null object\nInstalment-per-cent                  500 non-null int64\nGuarantors                           500 non-null object\nDuration-in-Current-address          500 non-null int64\nMost-valuable-available-asset        500 non-null int64\nAge-years                            500 non-null int64\nConcurrent-Credits                   500 non-null object\nType-of-apartment                    500 non-null int64\nNo-of-Credits-at-this-Bank           500 non-null object\nOccupation                           500 non-null int64\nNo-of-dependents                     500 non-null int64\nTelephone                            500 non-null int64\nForeign-Worker                       500 non-null int64\ndtypes: int64(11), object(8)\nmemory usage: 74.3+ KB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# CLEAN DATA"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Clean old_applicants Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.isnull().sum()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Credit-Application-Result              0\nAccount-Balance                        0\nDuration-of-Credit-Month               0\nPayment-Status-of-Previous-Credit      0\nPurpose                                0\nCredit-Amount                          0\nValue-Savings-Stocks                   0\nLength-of-current-employment           0\nInstalment-per-cent                    0\nGuarantors                             0\nDuration-in-Current-address          344\nMost-valuable-available-asset          0\nAge-years                             12\nConcurrent-Credits                     0\nType-of-apartment                      0\nNo-of-Credits-at-this-Bank             0\nOccupation                             0\nNo-of-dependents                       0\nTelephone                              0\nForeign-Worker                         0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "_Duration-in-Current-address_ and _Age-years_ requires some cleanup:\n\n* _Duration-in-Current-address_: immediately removing this attribute since â‰ˆ68% of the field is null\n\n* _Age-years_: will handle this cleanup after splitting old_applications into training and testing set. Otherwise I am violating a core tenent in the machine learning procedure. I cannot assume I know the median value of the entire data set to make predictions. I can only assume I know the median value of the training set. In other words I don't want to fit information from my testing set into my training set.\n\nNote:\n1. Use the median age of _Age-years_ column to impute missing values.\n* Dropping _Duration-in-Current-address_ becasue more than half field is null... â‰ˆ 69%"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# calculate percent of null values in Duration-in-Current-address\nold_applicants[\"Duration-in-Current-address\"].isnull().sum()/old_applicants[\"Duration-in-Current-address\"].shape[0]",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0.688"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Dropping Duration-in-Current-address becasue more than half field is null\nold_applicants.drop('Duration-in-Current-address', axis=1, inplace=True)\n# there are no more no values in the old_applicants dataset\nold_applicants.isnull().sum()",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "Credit-Application-Result             0\nAccount-Balance                       0\nDuration-of-Credit-Month              0\nPayment-Status-of-Previous-Credit     0\nPurpose                               0\nCredit-Amount                         0\nValue-Savings-Stocks                  0\nLength-of-current-employment          0\nInstalment-per-cent                   0\nGuarantors                            0\nMost-valuable-available-asset         0\nAge-years                            12\nConcurrent-Credits                    0\nType-of-apartment                     0\nNo-of-Credits-at-this-Bank            0\nOccupation                            0\nNo-of-dependents                      0\nTelephone                             0\nForeign-Worker                        0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Clean new_applicants Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_applicants.isnull().sum()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "Account-Balance                      0\nDuration-of-Credit-Month             0\nPayment-Status-of-Previous-Credit    0\nPurpose                              0\nCredit-Amount                        0\nValue-Savings-Stocks                 0\nLength-of-current-employment         0\nInstalment-per-cent                  0\nGuarantors                           0\nDuration-in-Current-address          0\nMost-valuable-available-asset        0\nAge-years                            0\nConcurrent-Credits                   0\nType-of-apartment                    0\nNo-of-Credits-at-this-Bank           0\nOccupation                           0\nNo-of-dependents                     0\nTelephone                            0\nForeign-Worker                       0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "As indicated in the code above, and using new_applicants.info() earlier, the new_applicants data set has no null values. Will leave this data set alone for now since there is no immediate clean up needed. However, might be some columns that are removed later from the dataset for other reasons."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Get Dummy Variables"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The string values need to be converted to numerical values"
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.head(10)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Credit-Application-Result</th>\n      <th>Account-Balance</th>\n      <th>Duration-of-Credit-Month</th>\n      <th>Payment-Status-of-Previous-Credit</th>\n      <th>Purpose</th>\n      <th>Credit-Amount</th>\n      <th>Value-Savings-Stocks</th>\n      <th>Length-of-current-employment</th>\n      <th>Instalment-per-cent</th>\n      <th>Guarantors</th>\n      <th>Most-valuable-available-asset</th>\n      <th>Age-years</th>\n      <th>Concurrent-Credits</th>\n      <th>Type-of-apartment</th>\n      <th>No-of-Credits-at-this-Bank</th>\n      <th>Occupation</th>\n      <th>No-of-dependents</th>\n      <th>Telephone</th>\n      <th>Foreign-Worker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>4</td>\n      <td>Paid Up</td>\n      <td>Other</td>\n      <td>1494</td>\n      <td>Â£100-Â£1000</td>\n      <td>&lt; 1yr</td>\n      <td>1</td>\n      <td>None</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>4</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>1494</td>\n      <td>Â£100-Â£1000</td>\n      <td>&lt; 1yr</td>\n      <td>1</td>\n      <td>None</td>\n      <td>1</td>\n      <td>29.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>4</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>1544</td>\n      <td>None</td>\n      <td>1-4 yrs</td>\n      <td>2</td>\n      <td>None</td>\n      <td>1</td>\n      <td>42.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>More than 1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>4</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>3380</td>\n      <td>None</td>\n      <td>1-4 yrs</td>\n      <td>1</td>\n      <td>None</td>\n      <td>1</td>\n      <td>37.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Creditworthy</td>\n      <td>No Account</td>\n      <td>6</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>343</td>\n      <td>None</td>\n      <td>&lt; 1yr</td>\n      <td>4</td>\n      <td>None</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>6</td>\n      <td>No Problems (in this bank)</td>\n      <td>Home Related</td>\n      <td>362</td>\n      <td>&lt; Â£100</td>\n      <td>&lt; 1yr</td>\n      <td>4</td>\n      <td>None</td>\n      <td>3</td>\n      <td>52.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>More than 1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Non-Creditworthy</td>\n      <td>No Account</td>\n      <td>6</td>\n      <td>Some Problems</td>\n      <td>Home Related</td>\n      <td>433</td>\n      <td>Â£100-Â£1000</td>\n      <td>&lt; 1yr</td>\n      <td>4</td>\n      <td>None</td>\n      <td>2</td>\n      <td>24.0</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Creditworthy</td>\n      <td>No Account</td>\n      <td>6</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>454</td>\n      <td>None</td>\n      <td>&lt; 1yr</td>\n      <td>3</td>\n      <td>None</td>\n      <td>2</td>\n      <td>22.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Creditworthy</td>\n      <td>No Account</td>\n      <td>6</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>484</td>\n      <td>None</td>\n      <td>1-4 yrs</td>\n      <td>3</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>28.0</td>\n      <td>Other Banks/Depts</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Creditworthy</td>\n      <td>Some Balance</td>\n      <td>6</td>\n      <td>Paid Up</td>\n      <td>Home Related</td>\n      <td>660</td>\n      <td>Â£100-Â£1000</td>\n      <td>1-4 yrs</td>\n      <td>2</td>\n      <td>None</td>\n      <td>1</td>\n      <td>23.0</td>\n      <td>Other Banks/Depts</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  Credit-Application-Result Account-Balance  Duration-of-Credit-Month  \\\n0              Creditworthy    Some Balance                         4   \n1              Creditworthy    Some Balance                         4   \n2              Creditworthy    Some Balance                         4   \n3              Creditworthy    Some Balance                         4   \n4              Creditworthy      No Account                         6   \n5              Creditworthy    Some Balance                         6   \n6          Non-Creditworthy      No Account                         6   \n7              Creditworthy      No Account                         6   \n8              Creditworthy      No Account                         6   \n9              Creditworthy    Some Balance                         6   \n\n  Payment-Status-of-Previous-Credit       Purpose  Credit-Amount  \\\n0                           Paid Up         Other           1494   \n1                           Paid Up  Home Related           1494   \n2        No Problems (in this bank)  Home Related           1544   \n3        No Problems (in this bank)  Home Related           3380   \n4                           Paid Up  Home Related            343   \n5        No Problems (in this bank)  Home Related            362   \n6                     Some Problems  Home Related            433   \n7                           Paid Up  Home Related            454   \n8                           Paid Up  Home Related            484   \n9                           Paid Up  Home Related            660   \n\n  Value-Savings-Stocks Length-of-current-employment  Instalment-per-cent  \\\n0           Â£100-Â£1000                        < 1yr                    1   \n1           Â£100-Â£1000                        < 1yr                    1   \n2                 None                      1-4 yrs                    2   \n3                 None                      1-4 yrs                    1   \n4                 None                        < 1yr                    4   \n5               < Â£100                        < 1yr                    4   \n6           Â£100-Â£1000                        < 1yr                    4   \n7                 None                        < 1yr                    3   \n8                 None                      1-4 yrs                    3   \n9           Â£100-Â£1000                      1-4 yrs                    2   \n\n  Guarantors  Most-valuable-available-asset  Age-years Concurrent-Credits  \\\n0       None                              1        NaN  Other Banks/Depts   \n1       None                              1       29.0  Other Banks/Depts   \n2       None                              1       42.0  Other Banks/Depts   \n3       None                              1       37.0  Other Banks/Depts   \n4       None                              1       27.0  Other Banks/Depts   \n5       None                              3       52.0  Other Banks/Depts   \n6       None                              2       24.0  Other Banks/Depts   \n7       None                              2       22.0  Other Banks/Depts   \n8        Yes                              1       28.0  Other Banks/Depts   \n9       None                              1       23.0  Other Banks/Depts   \n\n   Type-of-apartment No-of-Credits-at-this-Bank  Occupation  No-of-dependents  \\\n0                  2                          1           1                 2   \n1                  2                          1           1                 2   \n2                  2                More than 1           1                 2   \n3                  2                          1           1                 2   \n4                  2                          1           1                 1   \n5                  2                More than 1           1                 1   \n6                  1                          1           1                 2   \n7                  2                          1           1                 1   \n8                  2                          1           1                 1   \n9                  1                          1           1                 1   \n\n   Telephone  Foreign-Worker  \n0          1               2  \n1          1               2  \n2          1               1  \n3          1               1  \n4          1               1  \n5          1               1  \n6          1               1  \n7          1               1  \n8          1               1  \n9          1               1  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pd.options.display.max_columns = 30",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# np.where(old_applicants[\"Credit-Application-Result\"] == \"Creditworthy\", 1, 0)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants_dummies = \nold_applicants_dummies = pd.get_dummies(old_applicants, columns = ['Credit-Application-Result', 'Account-Balance', 'Payment-Status-of-Previous-Credit', 'Purpose', 'Value-Savings-Stocks', 'Length-of-current-employment', 'Guarantors', 'Concurrent-Credits', 'No-of-Credits-at-this-Bank'], drop_first=True)\n",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants_dummies.head()\n",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Duration-of-Credit-Month</th>\n      <th>Credit-Amount</th>\n      <th>Instalment-per-cent</th>\n      <th>Most-valuable-available-asset</th>\n      <th>Age-years</th>\n      <th>Type-of-apartment</th>\n      <th>Occupation</th>\n      <th>No-of-dependents</th>\n      <th>Telephone</th>\n      <th>Foreign-Worker</th>\n      <th>Credit-Application-Result_Non-Creditworthy</th>\n      <th>Account-Balance_Some Balance</th>\n      <th>Payment-Status-of-Previous-Credit_Paid Up</th>\n      <th>Payment-Status-of-Previous-Credit_Some Problems</th>\n      <th>Purpose_New car</th>\n      <th>Purpose_Other</th>\n      <th>Purpose_Used car</th>\n      <th>Value-Savings-Stocks_None</th>\n      <th>Value-Savings-Stocks_Â£100-Â£1000</th>\n      <th>Length-of-current-employment_4-7 yrs</th>\n      <th>Length-of-current-employment_&lt; 1yr</th>\n      <th>Guarantors_Yes</th>\n      <th>No-of-Credits-at-this-Bank_More than 1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>1494</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1494</td>\n      <td>1</td>\n      <td>1</td>\n      <td>29.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>1544</td>\n      <td>2</td>\n      <td>1</td>\n      <td>42.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>3380</td>\n      <td>1</td>\n      <td>1</td>\n      <td>37.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>343</td>\n      <td>4</td>\n      <td>1</td>\n      <td>27.0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   Duration-of-Credit-Month  Credit-Amount  Instalment-per-cent  \\\n0                         4           1494                    1   \n1                         4           1494                    1   \n2                         4           1544                    2   \n3                         4           3380                    1   \n4                         6            343                    4   \n\n   Most-valuable-available-asset  Age-years  Type-of-apartment  Occupation  \\\n0                              1        NaN                  2           1   \n1                              1       29.0                  2           1   \n2                              1       42.0                  2           1   \n3                              1       37.0                  2           1   \n4                              1       27.0                  2           1   \n\n   No-of-dependents  Telephone  Foreign-Worker  \\\n0                 2          1               2   \n1                 2          1               2   \n2                 2          1               1   \n3                 2          1               1   \n4                 1          1               1   \n\n   Credit-Application-Result_Non-Creditworthy  Account-Balance_Some Balance  \\\n0                                           0                             1   \n1                                           0                             1   \n2                                           0                             1   \n3                                           0                             1   \n4                                           0                             0   \n\n   Payment-Status-of-Previous-Credit_Paid Up  \\\n0                                          1   \n1                                          1   \n2                                          0   \n3                                          0   \n4                                          1   \n\n   Payment-Status-of-Previous-Credit_Some Problems  Purpose_New car  \\\n0                                                0                0   \n1                                                0                0   \n2                                                0                0   \n3                                                0                0   \n4                                                0                0   \n\n   Purpose_Other  Purpose_Used car  Value-Savings-Stocks_None  \\\n0              1                 0                          0   \n1              0                 0                          0   \n2              0                 0                          1   \n3              0                 0                          1   \n4              0                 0                          1   \n\n   Value-Savings-Stocks_Â£100-Â£1000  Length-of-current-employment_4-7 yrs  \\\n0                                1                                     0   \n1                                1                                     0   \n2                                0                                     0   \n3                                0                                     0   \n4                                0                                     0   \n\n   Length-of-current-employment_< 1yr  Guarantors_Yes  \\\n0                                   1               0   \n1                                   1               0   \n2                                   0               0   \n3                                   0               0   \n4                                   1               0   \n\n   No-of-Credits-at-this-Bank_More than 1  \n0                                       0  \n1                                       0  \n2                                       1  \n3                                       0  \n4                                       0  "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants_dummies.columns\n",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Index(['Duration-of-Credit-Month', 'Credit-Amount', 'Instalment-per-cent',\n       'Most-valuable-available-asset', 'Age-years', 'Type-of-apartment',\n       'Occupation', 'No-of-dependents', 'Telephone', 'Foreign-Worker',\n       'Credit-Application-Result_Non-Creditworthy',\n       'Account-Balance_Some Balance',\n       'Payment-Status-of-Previous-Credit_Paid Up',\n       'Payment-Status-of-Previous-Credit_Some Problems', 'Purpose_New car',\n       'Purpose_Other', 'Purpose_Used car', 'Value-Savings-Stocks_None',\n       'Value-Savings-Stocks_Â£100-Â£1000',\n       'Length-of-current-employment_4-7 yrs',\n       'Length-of-current-employment_< 1yr', 'Guarantors_Yes',\n       'No-of-Credits-at-this-Bank_More than 1'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Split old_appliants Data 1st Round"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# using given random state to obtain the same split\n# You should choose 70% to create the Estimation set and 30% to create the Validation set. \n# Set the Random Seed to 1 if you're using Alteryx.\n\nX = old_applicants_dummies.loc[:, ~old_applicants_dummies.columns.isin(['Credit-Application-Result_Non-Creditworthy'])].copy()\ny = y_dummy = old_applicants_dummies['Credit-Application-Result_Non-Creditworthy'].copy()\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, train_size = 0.7)\n\n",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# impute missing information w/ median value of training set. Age-years is the only feature with missing data.\ntraining_median = X_train.median()\nX_train = X_train.fillna(training_median)\nX_test = X_test.fillna(training_median)\n\nprint(training_median)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Duration-of-Credit-Month                             18.0\nCredit-Amount                                      2176.0\nInstalment-per-cent                                   3.0\nMost-valuable-available-asset                         2.0\nAge-years                                            33.0\nType-of-apartment                                     2.0\nOccupation                                            1.0\nNo-of-dependents                                      1.0\nTelephone                                             1.0\nForeign-Worker                                        1.0\nAccount-Balance_Some Balance                          0.0\nPayment-Status-of-Previous-Credit_Paid Up             1.0\nPayment-Status-of-Previous-Credit_Some Problems       0.0\nPurpose_New car                                       0.0\nPurpose_Other                                         0.0\nPurpose_Used car                                      0.0\nValue-Savings-Stocks_None                             1.0\nValue-Savings-Stocks_Â£100-Â£1000                       0.0\nLength-of-current-employment_4-7 yrs                  0.0\nLength-of-current-employment_< 1yr                    1.0\nGuarantors_Yes                                        0.0\nNo-of-Credits-at-this-Bank_More than 1                0.0\ndtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.isnull().sum()",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "Duration-of-Credit-Month                           0\nCredit-Amount                                      0\nInstalment-per-cent                                0\nMost-valuable-available-asset                      0\nAge-years                                          0\nType-of-apartment                                  0\nOccupation                                         0\nNo-of-dependents                                   0\nTelephone                                          0\nForeign-Worker                                     0\nAccount-Balance_Some Balance                       0\nPayment-Status-of-Previous-Credit_Paid Up          0\nPayment-Status-of-Previous-Credit_Some Problems    0\nPurpose_New car                                    0\nPurpose_Other                                      0\nPurpose_Used car                                   0\nValue-Savings-Stocks_None                          0\nValue-Savings-Stocks_Â£100-Â£1000                    0\nLength-of-current-employment_4-7 yrs               0\nLength-of-current-employment_< 1yr                 0\nGuarantors_Yes                                     0\nNo-of-Credits-at-this-Bank_More than 1             0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(350, 22)\n(150, 22)\n(350,)\n(150,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Removing Features Based On Variance"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_selection import VarianceThreshold\nselector = VarianceThreshold(threshold = 0.0)\nselector = selector.fit_transform(X_train)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.var(axis=0).round(3)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Duration-of-Credit-Month                               146.560\nCredit-Amount                                      7801794.006\nInstalment-per-cent                                      1.248\nMost-valuable-available-asset                            1.132\nAge-years                                              131.136\nType-of-apartment                                        0.282\nOccupation                                               0.000\nNo-of-dependents                                         0.139\nTelephone                                                0.242\nForeign-Worker                                           0.036\nAccount-Balance_Some Balance                             0.251\nPayment-Status-of-Previous-Credit_Paid Up                0.250\nPayment-Status-of-Previous-Credit_Some Problems          0.044\nPurpose_New car                                          0.076\nPurpose_Other                                            0.025\nPurpose_Used car                                         0.142\nValue-Savings-Stocks_None                                0.241\nValue-Savings-Stocks_Â£100-Â£1000                          0.211\nLength-of-current-employment_4-7 yrs                     0.189\nLength-of-current-employment_< 1yr                       0.249\nGuarantors_Yes                                           0.069\nNo-of-Credits-at-this-Bank_More than 1                   0.236\ndtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Notice Concurrent-Credits and Occupation have both been removed from the dataset. There are only 17 columns now.\nselector.var(axis=0).round(3)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "array([1.46141000e+02, 7.77950317e+06, 1.24500000e+00, 1.12900000e+00,\n       1.30762000e+02, 2.81000000e-01, 1.38000000e-01, 2.41000000e-01,\n       3.60000000e-02, 2.50000000e-01, 2.49000000e-01, 4.40000000e-02,\n       7.60000000e-02, 2.50000000e-02, 1.42000000e-01, 2.40000000e-01,\n       2.10000000e-01, 1.88000000e-01, 2.48000000e-01, 6.90000000e-02,\n       2.35000000e-01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# testing df_trfaining_corr dataset for low variance\nX_train.var(axis=0)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "Duration-of-Credit-Month                           1.465602e+02\nCredit-Amount                                      7.801794e+06\nInstalment-per-cent                                1.248465e+00\nMost-valuable-available-asset                      1.132345e+00\nAge-years                                          1.311363e+02\nType-of-apartment                                  2.818256e-01\nOccupation                                         0.000000e+00\nNo-of-dependents                                   1.386492e-01\nTelephone                                          2.418011e-01\nForeign-Worker                                     3.586574e-02\nAccount-Balance_Some Balance                       2.506836e-01\nPayment-Status-of-Previous-Credit_Paid Up          2.495375e-01\nPayment-Status-of-Previous-Credit_Some Problems    4.374949e-02\nPurpose_New car                                    7.620958e-02\nPurpose_Other                                      2.512485e-02\nPurpose_Used car                                   1.424478e-01\nValue-Savings-Stocks_None                          2.406877e-01\nValue-Savings-Stocks_Â£100-Â£1000                    2.106017e-01\nLength-of-current-employment_4-7 yrs               1.887515e-01\nLength-of-current-employment_< 1yr                 2.486205e-01\nGuarantors_Yes                                     6.896439e-02\nNo-of-Credits-at-this-Bank_More than 1             2.355792e-01\ndtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dropping columns with zero variance\n# X_train = X_train.drop(columns = ['Occupation'])",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# display dataset with columns dropped\n# X_train.columns",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Occupation is going to dropped from the dataset in the next section due to variance. Interestingly _Concurrent-Credits_ would have also been dropped due to having a variance of zero, but it was dropped from the dataset after running pd.get_dummies() function ealier. Therefore it did not appear in this section. I beleive this is due to it only having one value (i.e. it is dropped naturally because it only has one value _Other Banks/Depts_)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Split old_appliants Data 2nd Round"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# the first split allowed me to look at variance across all features that will be split.\n# this second round is allowing me to re-copy the original dataset and drop the attributes I do not want\n# in this case I am dropping Occupation due to variance\n# there is probably a more elegant way to do this, but I have not figured that out yet\n\nX = old_applicants_dummies.loc[:, ~old_applicants_dummies.columns.isin(['Credit-Application-Result_Non-Creditworthy', 'Occupation'])].copy()\ny = y_dummy = old_applicants_dummies['Credit-Application-Result_Non-Creditworthy'].copy()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, train_size = 0.7)\n",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# impute missing information w/ median value of training set. Age-years is the only feature with missing data.\ntraining_median = X_train.median()\nX_train = X_train.fillna(training_median)\nX_test = X_test.fillna(training_median)\n\nprint(training_median)",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Duration-of-Credit-Month                             18.0\nCredit-Amount                                      2176.0\nInstalment-per-cent                                   3.0\nMost-valuable-available-asset                         2.0\nAge-years                                            33.0\nType-of-apartment                                     2.0\nNo-of-dependents                                      1.0\nTelephone                                             1.0\nForeign-Worker                                        1.0\nAccount-Balance_Some Balance                          0.0\nPayment-Status-of-Previous-Credit_Paid Up             1.0\nPayment-Status-of-Previous-Credit_Some Problems       0.0\nPurpose_New car                                       0.0\nPurpose_Other                                         0.0\nPurpose_Used car                                      0.0\nValue-Savings-Stocks_None                             1.0\nValue-Savings-Stocks_Â£100-Â£1000                       0.0\nLength-of-current-employment_4-7 yrs                  0.0\nLength-of-current-employment_< 1yr                    1.0\nGuarantors_Yes                                        0.0\nNo-of-Credits-at-this-Bank_More than 1                0.0\ndtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.isnull().sum()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "Duration-of-Credit-Month                           0\nCredit-Amount                                      0\nInstalment-per-cent                                0\nMost-valuable-available-asset                      0\nAge-years                                          0\nType-of-apartment                                  0\nNo-of-dependents                                   0\nTelephone                                          0\nForeign-Worker                                     0\nAccount-Balance_Some Balance                       0\nPayment-Status-of-Previous-Credit_Paid Up          0\nPayment-Status-of-Previous-Credit_Some Problems    0\nPurpose_New car                                    0\nPurpose_Other                                      0\nPurpose_Used car                                   0\nValue-Savings-Stocks_None                          0\nValue-Savings-Stocks_Â£100-Â£1000                    0\nLength-of-current-employment_4-7 yrs               0\nLength-of-current-employment_< 1yr                 0\nGuarantors_Yes                                     0\nNo-of-Credits-at-this-Bank_More than 1             0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(350, 21)\n(150, 21)\n(350,)\n(150,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">Visualizations</span>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">Correlation</span>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">P-Value<span>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Logistic Regression"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create classifier as empty box\nLRC = LogisticRegression()",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# my classifer doesn't now anything about being credit worthy or not\n# need to use fit learning algorithm to train the classifier\nLRC.fit(X_train, y_train)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# let's take the classifier for a spin and make some predictions\nLRC.predict(X_test)",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "array([0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Score it on the test set\n# Using the default classification accuracy score\nLRC.score(X_test, y_test)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "0.76"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# get same score as above\n# from sklearn.metrics import classification_report\n# classification_report(y_test, LRC.predict(X_test))\n",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Decision Tree"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create classifer... right now it's just an empty box\ndectree = tree.DecisionTreeClassifier()\n",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# my classifier doesn't know anything about being credit worthy or not yet\n# to train the classifier, I need a learning algorithm\n# if a classifier is a box of rules, then the learning algorithm is the procedure that creates the rules\n# fit is my classifier, think of it as a synonym for find patterns in data\ndectree.fit(X_train, y_train)\n",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n            max_features=None, max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# now that the classifier has been trained let's take it for a spin\ndectree.predict(X_test)\n",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "array([0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=uint8)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Score it on the test set\n# Using the default classification accuracy score\ndectree.score(X_test, y_test)\n",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "0.6666666666666666"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "creditworthy_results = [\"Creditworthy\", \"Non-Creditworthy\"]",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "list(X.columns)",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": "['Duration-of-Credit-Month',\n 'Credit-Amount',\n 'Instalment-per-cent',\n 'Most-valuable-available-asset',\n 'Age-years',\n 'Type-of-apartment',\n 'No-of-dependents',\n 'Telephone',\n 'Foreign-Worker',\n 'Account-Balance_Some Balance',\n 'Payment-Status-of-Previous-Credit_Paid Up',\n 'Payment-Status-of-Previous-Credit_Some Problems',\n 'Purpose_New car',\n 'Purpose_Other',\n 'Purpose_Used car',\n 'Value-Savings-Stocks_None',\n 'Value-Savings-Stocks_Â£100-Â£1000',\n 'Length-of-current-employment_4-7 yrs',\n 'Length-of-current-employment_< 1yr',\n 'Guarantors_Yes',\n 'No-of-Credits-at-this-Bank_More than 1']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This output can be visualized\nimport pydot\nfrom sklearn.externals.six import StringIO\n\ndotfile = StringIO()\ntree.export_graphviz(dectree,\n                     out_file=dotfile,\n                     feature_names=list(X.columns),\n                     class_names=creditworthy_results,\n                     filled=True,\n                     rounded=True,\n                     impurity=False\n                    )\n(graph,)=pydot.graph_from_dot_data(dotfile.getvalue())\ngraph.write_png(\"./assets/dtree.png\")\ngraph.write_pdf(\"./assets/dtree.pdf\")",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This is a diagram of the visuals I saved to my repository. The diagram provides a visual representation of the decision tree. The nice thing about decision trees is that they are interpretable, and the tree diagram works the same way it would in code (i.e. you know exactly why the classifier makes a decision).\n\n![Displaying the visual I just created:](./assets/dtree.png)\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Boosted Tree (aka Gradient Boosting)\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create classifier... this is an empty box\ngbc = GradientBoostingClassifier()",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# my classifer doesn't now anything about being credit worthy or not\n# use fit algorithm to train the gbc classifier\ngbc.fit(X_train, y_train)",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n              learning_rate=0.1, loss='deviance', max_depth=3,\n              max_features=None, max_leaf_nodes=None,\n              min_impurity_decrease=0.0, min_impurity_split=None,\n              min_samples_leaf=1, min_samples_split=2,\n              min_weight_fraction_leaf=0.0, n_estimators=100,\n              presort='auto', random_state=None, subsample=1.0, verbose=0,\n              warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# take your classifier for a spin, make some predictions\ngbc.predict(X_test)",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "array([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Score it on the test set\n# Using the default classification accuracy score\ngbc.score(X_test, y_test)",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "0.7266666666666667"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Forest Model (aka Random Forest Model)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# classifier is empty box\nrf = RandomForestClassifier()",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# classifier doesn't know anything about being credit worthy\n# so need to use fit algorithm to train the classifier\n# fit(features, target)\nrf.fit(X_train, y_train)",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# take the trained classifier for a spin and make some predictions\nrf.predict(X_test)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Score it on the test set\n# Using the default classification accuracy score\nrf.score(X_test, y_test)",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "0.7466666666666667"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "BREAK",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'BREAK' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-66db536c6cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBREAK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'BREAK' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Test New Data Set\n\n* get dummies for new dataset\n* drop Occupation and Concurrent from data set. If needed, you might just select features based on previous section...\n* but if you need to drop columns then you can using the code in next cell"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\n# X = old_applicants_dummies.loc[:, ~old_applicants_dummies.columns.isin(['Credit-Application-Result_Non-Creditworthy', 'Occupation'])].copy()\n# y = y_dummy = old_applicants_dummies['Credit-Application-Result_Non-Creditworthy'].copy()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Correlation"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note:\n\nWhen when two features are highly correlated they are linearly dependent, and will have the same or similar effect on the dependent variable (target variable???). Therefore, when two features have high correlation, one of the two features can be dropped.\n\n??? using the funciton np.random.seed() allowed me to make random numbers predictable and replicable ???\n??? we randomize the order of data to affect how the model is trained (i.e. don't want order to affect how we learn)... order of the data  is not a part in determining if an applicant is creditworthy or not.... \nhttps://www.youtube.com/watch?v=nKW8Ndu7Mjw\n\n\n??? do i need to create dummy variables first, before doing the following steps... to find out start small with 2 columns and see if you get the same values???\n\nlabeled the categorical variable using scikit-learn's LabelEncoder() class to transform non-numberical data to numerical data types.\n\nThen calcualted each column's variance and removed items with low variance. In this case, I removed columns Concurrent-Credits and Occupation for both having a variance of zero; meaning they had the same value accross the entire field. \n\nthen generated correlation matrix with old_applicants.corr(), which I passed to a correlation heat-map using seaborn. \n\nI then wrote a script that allowed me to compare the correlation between features. If two features had a correlation higher than 0.7, then one of the features was removed. My features were selected once the dataset only had the columns with correlation less than 0.7.\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Selecting Features Based On Correlation"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note:\n\n[scikit-learn VerianceThreshold](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) can be used to remove features with low variance. The default variance is set at 0.0. In this case Concurrent-Credits and Occupation variability are equal to zero. They will be removed from the dataframe."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr = old_applicants_dummies.loc[:, ~old_applicants_dummies.columns.isin(['Concurrent-Credits','Occupation'])].copy()\ncorr = corr.corr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# GENERATE THE HEATMAP\nsns.heatmap(corr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The heatmap function automatically chooses the most correlated features, and I want to focus on features correlations to the target variable. Therfore I am assuming the more coreelatated a feature is to a target, the more useful it will be in my model. Also, correlation coefficient can be used to determine similar features (i.e. redundancies). To reduce overfitting my model, I will be using correlation to spot overfitting and remove redundant features.\nhttps://hub.packtpub.com/selecting-statistical-based-features-in-machine-learning-application/ \n<span style=\"color:red\">_this covers chapter 5... look at chapter 4 for additional details_</span>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# isolating correlations between features and the target variable\ncorr['Credit-Application-Result']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I'm ignoring the correlation for _Credit-Application-Result_ since it is the target variable. Then looking at all of the features that have correlations close to -1 or +1; since these are the features I am assuming will be useful. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# using pandas to filter features that have Â±0.2 correlations. \ncorr['Credit-Application-Result'].abs() > 0.7",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Every False in the preceding pandas Series represents a feature that has a correlation value between -.7 and .7 inclusive, while True values correspond to features with preceding correlation values .7 or less than -0.7.\n\nEach _False_ in the series above represents a feature correlation between Â±0.7 (inclusive). While, _True_ represents feature correlation values less than -0.7, or greater than 0.7. This can be plugged into the previous filter as a mask. I will assign it to a variable that represents highly correlated features and will drop the target variable. This should leave me with a list of highly correlated features."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plugging mask into previous pandas filter\nhighly_correlated_features = corr.columns[corr['Credit-Application-Result'].abs() > 0.7]\nhighly_correlated_features = highly_correlated_features.drop('Credit-Application-Result')\nhighly_correlated_features",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# KNN"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.score(X_test, y_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "NOW YOU CAN RUN CORR ON THE DATA",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "BREAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Logistic Regression"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants_dummies.drop('Credit-Application-Result_Non-Creditworthy', axis=1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_dummy = old_applicants_dummies.loc[:, ~old_applicants_dummies.columns.isin(['Credit-Application-Result_Non-Creditworthy'])]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# y_dummy = old_applicants_dummies['Credit-Application-Result_Non-Creditworthy']\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 1)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_train.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_train['Age-years'].head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# train_dummy_median = X_train_dummy.median()\n# X_train_dummy = X_train_dummy.fillna(train_dummy_median)\n# X_test_dummy = X_test_dummy.fillna(train_dummy_median)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X_train_dummy['Age-years'].head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# from sklearn.linear_model import LogisticRegression",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "logmodel = LogisticRegression()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "logmodel.fit(X_train, y_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "predictions = logmodel.predict(X_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classification_report(y_test, predictions)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "accuracy_score(y_test, predictions)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Feature Selection"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import warnings\n# warnings.filterwarnings(\"ignore\")\n# from sklearn.model_selection import train_test_split\n# from sklearn.svm import SVC\n# from sklearn.metrics import confusion_matrix\n# np.random.seed(1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">START: Change variable name old_applicants to something not referencing corr</span>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Pearson correlation is the defaut for pandas.corr() function. In this case I will use it to measure the relationship between columns. Pearson correlation requires each column be normall distributed (which I am not assuming). Although the recommended threshold for ignoring this threshold is set at greater than 500, I am going to ignore this requirement because the shape of this dataset is right at 500 (meaning my dataset is large).\nhttps://hub.packtpub.com/selecting-statistical-based-features-in-machine-learning-application/"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_correlation = old_applicants.copy()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# encode the categorciacl variables\nlabel_encoder = LabelEncoder()\n# encode the categorciacl variables\nlabel_encoder = LabelEncoder()\ndf_correlation.iloc[:,0] = label_encoder.fit_transform(df_correlation.iloc[:,0]).astype('float64')\ndf_correlation.iloc[:,1] = label_encoder.fit_transform(df_correlation.iloc[:,1]).astype('float64')\ndf_correlation.iloc[:,2] = label_encoder.fit_transform(df_correlation.iloc[:,2])\ndf_correlation.iloc[:,3] = label_encoder.fit_transform(df_correlation.iloc[:,3]).astype('float64')\ndf_correlation.iloc[:,4] = label_encoder.fit_transform(df_correlation.iloc[:,4]).astype('float64')\ndf_correlation.iloc[:,5] = label_encoder.fit_transform(df_correlation.iloc[:,5])\ndf_correlation.iloc[:,6] = label_encoder.fit_transform(df_correlation.iloc[:,6]).astype('float64')\ndf_correlation.iloc[:,7] = label_encoder.fit_transform(df_correlation.iloc[:,7]).astype('float64')\ndf_correlation.iloc[:,8] = label_encoder.fit_transform(df_correlation.iloc[:,8])\ndf_correlation.iloc[:,9] = label_encoder.fit_transform(df_correlation.iloc[:,9]).astype('float64')\ndf_correlation.iloc[:,10] = label_encoder.fit_transform(df_correlation.iloc[:,10])\ndf_correlation.iloc[:,11] = label_encoder.fit_transform(df_correlation.iloc[:,11])\ndf_correlation.iloc[:,12] = label_encoder.fit_transform(df_correlation.iloc[:,12])\ndf_correlation.iloc[:,13] = label_encoder.fit_transform(df_correlation.iloc[:,13]).astype('float64')\ndf_correlation.iloc[:,14] = label_encoder.fit_transform(df_correlation.iloc[:,14])\ndf_correlation.iloc[:,15] = label_encoder.fit_transform(df_correlation.iloc[:,15]).astype('float64')\ndf_correlation.iloc[:,16] = label_encoder.fit_transform(df_correlation.iloc[:,16])\ndf_correlation.iloc[:,17] = label_encoder.fit_transform(df_correlation.iloc[:,17])\ndf_correlation.iloc[:,18] = label_encoder.fit_transform(df_correlation.iloc[:,18])\n\n\n\n\n\n\n\n\n# # encode the categorciacl variables\n# label_encoder = LabelEncoder()\n# # encode the categorciacl variables\n# label_encoder = LabelEncoder()\n# old_applicants.iloc[:,0] = label_encoder.fit_transform(old_applicants.iloc[:,0]).astype('float64')\n# old_applicants.iloc[:,1] = label_encoder.fit_transform(old_applicants.iloc[:,1]).astype('float64')\n# old_applicants.iloc[:,2] = label_encoder.fit_transform(old_applicants.iloc[:,2])\n# old_applicants.iloc[:,3] = label_encoder.fit_transform(old_applicants.iloc[:,3]).astype('float64')\n# old_applicants.iloc[:,4] = label_encoder.fit_transform(old_applicants.iloc[:,4]).astype('float64')\n# old_applicants.iloc[:,5] = label_encoder.fit_transform(old_applicants.iloc[:,5])\n# old_applicants.iloc[:,6] = label_encoder.fit_transform(old_applicants.iloc[:,6]).astype('float64')\n# old_applicants.iloc[:,7] = label_encoder.fit_transform(old_applicants.iloc[:,7]).astype('float64')\n# old_applicants.iloc[:,8] = label_encoder.fit_transform(old_applicants.iloc[:,8])\n# old_applicants.iloc[:,9] = label_encoder.fit_transform(old_applicants.iloc[:,9]).astype('float64')\n# old_applicants.iloc[:,10] = label_encoder.fit_transform(old_applicants.iloc[:,10])\n# old_applicants.iloc[:,11] = label_encoder.fit_transform(old_applicants.iloc[:,11])\n# old_applicants.iloc[:,12] = label_encoder.fit_transform(old_applicants.iloc[:,12])\n# old_applicants.iloc[:,13] = label_encoder.fit_transform(old_applicants.iloc[:,13]).astype('float64')\n# old_applicants.iloc[:,14] = label_encoder.fit_transform(old_applicants.iloc[:,14])\n# old_applicants.iloc[:,15] = label_encoder.fit_transform(old_applicants.iloc[:,15]).astype('float64')\n# old_applicants.iloc[:,16] = label_encoder.fit_transform(old_applicants.iloc[:,16])\n# old_applicants.iloc[:,17] = label_encoder.fit_transform(old_applicants.iloc[:,17])\n# old_applicants.iloc[:,18] = label_encoder.fit_transform(old_applicants.iloc[:,18])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Label Encoder somehow removes my null Age-years values\ndf_correlation.isnull().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "BREAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# X = old_applicants[['Age-years', 'Account-Balance', 'Duration-of-Credit-Month','Payment-Status-of-Previous-Credit']].copy()\n# y = old_applicants['Credit-Application-Result'].copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## This code works to impute median value on age, but I want to paly around with Imputer transformer instead\n\n# # median age to impute missing values with\n# train_imputeAge = old_applicants['Age-years'].median()\n# train_imputeAge\n\n# # fill missing age values with imputed values\n# train['Age-years'].fillna(train_imputeAge, inplace=True)\n\n# # calculate average of ages after imputing the mean value\n# train['Age-years'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">Red Flag... imputing values before splitting is improper approach</span>\nNote that we aren't implementing any grid searching here, just a plain fit. We see that our model boasts a 66% accuracy rate (not great, but that's not the point). The important thing to note here is that both the training and the testing set of X were imputed using the mean of the entire X matrix. This is in direct violation of a core tenet of the machine learning procedure. We cannot assume that we know the mean of the entire dataset when predicting the test set's response values. Simply put, our KNN model is using information gained from the testing set to fit to the training set. This is a big red flag. These values will have to be imputed after the split. However, my data might already be split into training and testing data.\nhttps://subscription.packtpub.com/book/big_data_and_business_intelligence/9781787287600/3/ch03lvl1sec28/dealing-with-missing-values-in-a-dataset?_ga=2.100741634.2075634726.1552106478-132390188.1552018386"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import Imputer module from the scikit-learn preprocessing class\nfrom sklearn.preprocessing import Imputer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# use parameter strategy, and set it to median to define how you want to impute values into your dataset\nimputer = Imputer(strategy='median')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# call the fit_transform method to create a new object\ntain_imputed = imputer.fit_transform(old_applicants[['Age-years']])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Imputer output is not a pandas DataFrame, but a NumPy array\ntype(tain_imputed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# mean of Age-years before imputing median values on missing records\nold_applicants['Age-years'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# replace Age-years of original dataset with imputed NumPy array... previous records with NaN value will now contain the median 33\ntraold_applicantsin['Age-years'] = tain_imputed",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "type(old_applicants['Age-years'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# average Age-years has changed to reflect the mean with imputed values included\nold_applicants['Age-years'].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color:red\">BREAK CORRELATION</span>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "BREAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note: \n\nNotice there are still 17 columns, meaning no features have correlation of 0.7 or higher. Therefore no features will be removed from the dataset based on correlation value."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "columns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.7:\n            if columns[j]:\n                columns[j] = False\n\n# print(old_applicants.shape)\n# print(columns)\n# print(old_applicants.columns)\n\nselected_columns = old_applicants.columns[columns]\ndata = old_applicants[selected_columns]\n\n######\n######\n######\n\nselected_columns = selected_columns[1:].values\nimport statsmodels.formula.api as sm\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n#     print(numVars)\n    for i in range(0, numVars):\n        print(x.shape)\n        print(Y.shape)\n        print(i)\n        model = sm.OLS(Y, x[:,i])\n        fit = model.fit()\n        print(fit.pvalues)\n        print(pearsonr(x[:,i],Y))\n        maxVar = max(fit.pvalues).astype(float)\n#         print(maxVar)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (fit.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    fit.summary()\n#     print(x)\n#     print(columns)\n    return x, columns\n\nSL = 0.05 # eliminating features which have p > SL... p-value gives us the probability of finding the observed or a more extreme result when the null hypothesis is true. So when the p-value increases with the removal or addition of a feature, the probability of obtaining the observed results also increases.\ndata_modeled, selected_columns = backwardElimination(data.iloc[:,1:].values, data.iloc[:,0].values, SL, selected_columns)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pearsonr(data['Account-Balance'], data['Credit-Application-Result'])\n# data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# BREAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# OLS: https://www.youtube.com/watch?v=L_h7XFUGWAk\nselected_columns = selected_columns[1:].values\nimport statsmodels.formula.api as sm\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(Y, x).fit()\n        print(regressor_OLS.pvalues)        \n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        print(maxVar)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    regressor_OLS.summary()\n#     print(x)\n#     print(columns)\n    return x, columns\n\nSL = 0.05 # eliminating features which have p > SL... p-value gives us the probability of finding the observed or a more extreme result when the null hypothesis is true. So when the p-value increases with the removal or addition of a feature, the probability of obtaining the observed results also increases.\ndata_modeled, selected_columns = backwardElimination(data.iloc[:,1:].values, data.iloc[:,0].values, SL, selected_columns)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for i in data:\n    print(i)\n    print(\"p-val:\",pearsonr(data[i], result['diagnosis'])[0])\n    print(\"Corr: \",pearsonr(data[i], result['diagnosis'])[1])\n    print()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is target value\nresult = pd.DataFrame()\nresult['diagnosis'] = data.iloc[:,0]\nresult['diagnosis'].head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this dataframe of downselected features\ndata = pd.DataFrame(data = data_modeled, columns = selected_columns)\ndata.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note:\n\nThe data set has been downselected to 6 features:\n* _Account-Balance_\n* _Duration-of-Credit-Month_\n* _Payment-Status-of-Previous-Credit_\n* _Length-of-current-employment_\n* _Instalment-per-cent_\n* _Most-valuable-available-asset_"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Visualizing the Data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=data, x=result['diagnosis'], hue='Account-Balance')\n# sns.distplot(data=data, x=result['diagnosis'], hue='Account-Balance')\n# sns.distplot(data['Account-Balance'][result['diagnosis']==0, color='b', label = 'Crediworthy', kde=False)\n# sns.distplot(data['Account-Balance'], color='r', label = 'Non-Crediworthy', kde=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style=\"color: red\">BREAK</span>\n\nfix graphs... used original table explain that you are using them out of simplicity... then go into stats models"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# analyze the results of credit applicatons\n\nsns.countplot(data=old_applicants, x=\"Credit-Application-Result\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x='Credit-Application-Result', hue='Account-Balance')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Account-Balance\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Duration-of-Credit-Month\")\n# ax.legend(loc=4)\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., ).set_title(\"Duration-of-Credit-Month\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Payment-Status-of-Previous-Credit\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Length-of-current-employment\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Instalment-per-cent\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Most-valuable-available-asset\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Account-Balance\n# Duration-of-Credit-Month\n# Payment-Status-of-Previous-Credit\n# Length-of-current-employment\n# Instalment-per-cent\n# Most-valuable-available-asset",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x='Credit-Application-Result', hue='Account-Balance')\n# sns.countplot(data=data, x=result['diagnosis'], hue='Account-Balance')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Taking a look at relationship between the target variable (i.e. _Credit-Application-Result_) and all other features in the training set."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There are more creditworthy applicants (â‰ˆ350) vs non-creditworth applicants (â‰ˆ150)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Out of all the applicantion results who was creditworth and who was not credithworthy in regards to Account-Balance. More people were deemed Creditworth if they had some balance."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Tough to determine any relationship regarding Duration-of-Credit-Month."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Regarding payment-Status-of-Previous-Credit, More people were marked as creditworthy if they were  "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dummy variables\n\n# response variable\n\"Credit-Application-Result_Non-Creditworthy\" \n\n# target variables\n\"Duration-of-Credit-Month\"\n\"Credit-Amount\"\n\"Instalment-per-cent\"\n\"Most-valuable-available-asset\"\n\"Age-years\"\n\"Type-of-apartment\"\n\"No-of-dependents\"\n\"Telephone\"\n\"Foreign-Worker\"\n\"Account-Balance_Some Balance\"\n\"Payment-Status-of-Previous-Credit_Paid Up\"\n\"Payment-Status-of-Previous-Credit_Some Problems\"\n\"Purpose_New car\"\n\"Purpose_Other\"\n\"Purpose_Used car\"\n\"Value-Savings-Stocks_None\"\n\"Value-Savings-Stocks_Â£100-Â£1000\"\n\"Length-of-current-employment_4-7 yrs\"\n\"Length-of-current-employment_< 1yr\"\n\"Guarantors_Yes\"\n\"No-of-Credits-at-this-Bank_More than 1\"\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=train, x=\"Credit-Application-Result\", hue=\"Purpose\")\n# More people were marked as creditworthy if the purpose was home related",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=train, x=\"Credit-Application-Result\", hue=\"Credit-Amount\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# bins = 5000\n# x = old_applicants[\"Credit-Amount\"][old_applicants[\"Credit-Application-Result\"] == \"Creditworthy\"] \n# y = old_applicants[\"Credit-Amount\"][old_applicants[\"Credit-Application-Result\"] == \"Non-Creditworthy\"] \n\n# plt.hist(x, bins, alpha=0.5, label='x')\n# plt.hist(y, bins, alpha=0.5, label='y')\n# plt.legend(loc='upper right')\n# plt.show()\n\n\n\n# the histogram of the data\n# plt.hist(train[\"Credit-Amount\"], bins=1000)\n# plt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Value-Savings-Stocks\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Guarantors\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Age-years\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I don't know how _Age_ didn't make the list. Will need to investigate further."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# https://markhneedham.com/blog/2013/01/27/pythonnumpy-selecting-specific-column-in-2d-array/\n# To select specific column use the following format... basically stating select all rows from pecific index\n# zeroth column is Credit-Application-Result\nselector[:,0]\n\n# Account Balance has index 1\nselector[:,1]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Concurrent-Credits\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Type-of-apartment\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"No-of-Credits-at-this-Bank\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Occupation\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"No-of-dependents\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Telephone\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=old_applicants, x=\"Credit-Application-Result\", hue=\"Foreign-Worker\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# fig = plt.figure(figsize = (20, 25))\n# j = 0\n# for i in data.columns:\n#     plt.subplot(6, 4, j+1)\n#     j += 1\n#     sns.distplot(data[i][result['diagnosis']==0], color='g', label = 'Creditworthy', kde=False)\n#     sns.distplot(data[i][result['diagnosis']==1], color='r', label = 'Non-Crediworthy', kde=False)\n#     plt.legend(loc='best')\n# fig.suptitle('Default Risk Data Analysis')\n# fig.tight_layout()\n# fig.subplots_adjust(top=0.95)\n# plt.savefig(\"./assets/down selected features.png\", psi=300)\n# plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# selector[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=selector[:,0:2], x=selector[:,0], hue=selector[:,1])\n# sns.distplot(data[i][result['diagnosis']==0], color='g', label = 'Creditworthy', kde=False)\n# sns.distplot(data[0][result['diagnosis']==1], color='r', label = 'Non-Crediworthy', kde=False)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=selector[:,0:2], x=selector[:,0], hue=selector[:,1])\n# sns.countplot(data=old_applicants, x='Credit-Application-Result', hue='Account-Balance')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=selector[:,0:2], x=selector[:,0], hue=selector[:,1])\n# sns.countplot(data=old_applicants, x='Account-Balance', hue='Credit-Application-Result')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# sns.countplot(data=train, x=\"Credit-Application-Result\", hue=\"Account-Balance\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants[\"Account-Balance\"].unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# data[\"Account-Balance\"].unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# data[\"Length-of-current-employment\"].unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# test for variance across dataset\n# data.var(axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants.var(axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# BREAK",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Look into correlations for the following fields:\n# possPredictors = [\"Account-Balance\",\n#                   \"Payment-Status-of-Previous-Credit\",\n#                   \"Purpose\",\n#                   \"Credit-Amount\",\n#                   \"Value-Savings-Stocks\",\n#                   \"Length-of-current-employment\",\n#                   \"Instalment-per-cent\",\n#                   \"Guarantors\",\n#                   \"Most-valuable-available-asset\",\n#                   \"Age-years\",\n#                   \"Concurrent-Credits\",\n#                   \"Type-of-apartment\",\n#                   \"No-of-Credits-at-this-Bank\",\n#                   \"Occupation\",\n#                   \"No-of-dependents\",\n#                   \"Telephone\",\n#                   \"Foreign-Worker\"\n#                 ]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# old_applicants[\"Credit-Application-Result\"]=old_applicants[\"Credit-Application-Result\"].astype('category').cat.codes\n# old_applicants[\"Account-Balance\"]=old_applicants[\"Account-Balance\"].astype('category').cat.codes\n# old_applicants[\"Credit-Application-Result\"].dtype\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# first create dummies, and drop unwanted va\n\n# https://code.i-harness.com/en/q/186322a\n# https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n# pearson(x,y)... or predictor and target\n# Where the first value in the tuple is the correlation value, and second is the p-value.\n# creditworthy = np.where(old_applicants[\"Credit-Application-Result\"]==\"Creditworthy\", 1, 0)\n\nfrom scipy.stats import pearsonr\nfor i in data:\n    print(i)\n    print(\"p-val:\",pearsonr(data[i], result['diagnosis'])[0])\n    print(\"Corr: \",pearsonr(data[i], result['diagnosis'])[1])\n    print()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# from scipy.stats import spearmanr\n# for i in data:\n#     print(i)\n#     print(\"p-val:\",spearmanr(data[i], result['diagnosis'])[0])\n#     print(\"Corr: \",spearmanr(data[i], result['diagnosis'])[1])\n#     print()\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "BREAK\n# pearsonr(old_applicants[\"Credit-Amount\"], creditworthy)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.info()\n# old_applicants.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# data_cols = [\"Credit-Application-Result\",\n#              \"Account-Balance\",\n#              \"Payment-Status-of-Previous-Credit\",\n#              \"Purpose\",\n#              \"Value-Savings-Stocks\",\n#              \"Guarantors\",\n#              \"Concurrent-Credits\",\n#              \"No-of-Credits-at-this-Bank\"]\n\n# label_encoder = LabelEncoder()\n# for i in data_cols:\n#     data.loc[:,i] = label_encoder.fit_transform(data.loc[:,i]).astype('float64')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dummy columns\ndummy_cols = [\"Account-Balance\", \"Purpose\"]\n\n# Purpose_Home Related, Purpose_New car, Purpose_Other, Purpose_Used car\n# Account-Balance_No Account, Account-Balance_Some Balance\n\nold_applicants = pd.get_dummies(old_applicants, columns=dummy_cols, drop_first=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.iloc[0:5,0:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants[\"Credit-Application-Result\"].unique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pearsonr(old_applicants[\"Account-Balance\"], old_applicants[\"Credit-Application-Result\"])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "break\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = old_applicants.copy()\n# data = data.iloc[:,1:-1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_cols = [\"Credit-Application-Result\",\n             \"Account-Balance\",\n             \"Payment-Status-of-Previous-Credit\",\n             \"Purpose\",\n             \"Value-Savings-Stocks\",\n             \"Guarantors\",\n             \"Concurrent-Credits\",\n             \"No-of-Credits-at-this-Bank\"]\n\nlabel_encoder = LabelEncoder()\nfor i in data_cols:\n    data.loc[:,i] = label_encoder.fit_transform(data.loc[:,i]).astype('float64')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "corr = data.corr()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sns.heatmap(corr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# # COLORMAPS\n\n# # use cmap to set the chart colors\n# cmap = sns.choose_colorbrewer_palette(data_type = \"d\") # set data_type to d, q, or s",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# CORRELATION MATRIX\n# def correlationMatrix(dataset,suffix):\n#     corr = dataset.corr(method='pearson')\n    \n#     # Generate a mask for the upper triangle\n#     mask = np.zeros_like(corr, dtype=np.bool)\n#     mask[np.triu_indices_from(mask)] = True\n\n#     # Set up the matplotlib figure\n# #     fig, ax = plt.subplots(figsize=(10, 6))\n#     fig, ax = plt.subplots()\n\n#     # Draw the heatmap with the mask and correct aspect ratio\n#     sns.heatmap(corr, annot=True, fmt='.4f',\n#                 cmap=cmap, cbar=True, ax=ax, mask = mask,\n#                 square=False, linewidths=.5,cbar_kws={\"shrink\": .5})\n#     ax.set_title('Heatmap', fontsize = 18)\n#     ax.set_xlabel('Variable 1', fontsize = 15)\n#     ax.set_ylabel('Variable 2', fontsize = 15)\n#     ax.set_yticklabels(ax.get_yticklabels(), rotation=\"horizontal\", fontsize = 10)\n#     ax.set_xticklabels(ax.get_xticklabels(), fontsize = 10)\n#     plt.tight_layout()\n#     plt.savefig('./assets/pearsonCorrelation_{}'.format(suffix), dpi = 300, bbox_inches='tight', pad_inches=0.0)\n#     plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correlationMatrix(corr,\"old_applicants\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correlationMatrix(old_applicants,\"old_applicants\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correlationMatrix(new_applicants,\"new_applicants\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# LOGISTIC REGRESSION"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dummy columns\ndummy_cols = [\"Account-Balance\", \"Purpose\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Purpose_Home Related, Purpose_New car, Purpose_Other, Purpose_Used car\n# Account-Balance_No Account, Account-Balance_Some Balance\n\nold_applicants = pd.get_dummies(old_applicants, columns=dummy_cols, drop_first=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "old_applicants.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_applicants = pd.get_dummies(new_applicants, columns=dummy_cols)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_applicants.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# <span style = \"color:red\">I think X & y need to be split into train & test set... not predict on new_applicants dataset yet</span>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Dummies:'Account-Balance_No Account', 'Account-Balance_Some Balance', \n# Dummies:'Purpose_Home Related', 'Purpose_New car', 'Purpose_Used car'\n\n# create list of feature names\nfeature_cols = [\"Credit-Amount\",\n                \"Account-Balance_Some Balance\",\n                \"Purpose_New car\",\n                \"Purpose_New car\",\n                \"Purpose_Used car\"\n               ]\n\n# store feature matrix in \"X\"... old_applicants data featres\nX_train = old_applicants[feature_cols]\n\n# store response vector in \"y\"... train data target\ny_train = old_applicants[\"Credit-Application-Result\"]\n\n# predict new observations... new_applicants data\nX_test = new_applicants[feature_cols]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# import the class\nfrom sklearn.linear_model import LogisticRegression\n\n# instantiate the model (using the default parameters)\nlogreg = LogisticRegression()\n\n# fit the model with data\nlogreg.fit(X_train, y_train)\n\n# predict new targets based on new_applicants data\ny_pred = logreg.predict(X_test)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# looking at coefficient of the model, print the regression coefficient: https://www.youtube.com/watch?v=Eqv98w1ukZk\nprint(logreg.coef_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nprint(classification_report(y_train,y_pred))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correlationMatrix(old_applicants,\"old_applicants\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correlationMatrix(old_applicants ,\"test\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}